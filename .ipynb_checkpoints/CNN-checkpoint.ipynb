{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Library import NN_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_lib():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "#         import numpy as np\n",
    "        \n",
    "        self.epsilon = 1e-5\n",
    "        \n",
    "        self.act_func_map = {'relu':self.ReLU, 'sigmoid':self.sigmoid, 'tanh':self.tanh, \n",
    "                             'none':self.none, 'softmax':self.softmax}\n",
    "        \n",
    "        self.act_diff_map = {'relu':self.ReLU_diff, 'sigmoid':self.sigmoid_diff, \n",
    "                             'tanh':self.tanh_diff, 'softmax':self.softmax_diff}\n",
    "        \n",
    "        self.loss_error_map = {'mse':self.mse_error, 'binary_crossentropy':self.bincross_error, \n",
    "                               'categorical_crossentropy':self.catcross_error, \n",
    "                               'sparse_categorical_crossentropy':self.sparcat_error}\n",
    "        \n",
    "        self.metric_map = {'mse':self.calc_mse, 'binary_crossentropy':self.calc_bincross, \n",
    "                           'categorical_crossentropy':self.calc_catcross, \n",
    "                           'accuracy':self.calc_accuracy, \n",
    "                           'sparse_categorical_crossentropy':self.calc_sparcat}\n",
    "            \n",
    "    def tanh(self, X):\n",
    "        return np.divide( (np.exp(X) - np.exp(-X)), (np.exp(X) + np.exp(-X) + self.epsilon) )\n",
    "    \n",
    "    def none(self, X):\n",
    "        return X\n",
    "    \n",
    "    def sigmoid(self, X):\n",
    "        f = np.vectorize(self.stable_sigmoid)\n",
    "        return f(X)\n",
    "        \n",
    "    def stable_sigmoid(self, x):\n",
    "        if x >= 0:\n",
    "            z = np.exp(-x)\n",
    "            return 1 / (1 + z)\n",
    "        else:\n",
    "            z = np.exp(x)\n",
    "            return z / (1 + z)\n",
    "    \n",
    "    def ReLU(self, X):\n",
    "        return np.maximum(X, 0)\n",
    "    \n",
    "    def softmax(self, X):\n",
    "        X = X - np.max(X, axis=1, keepdims=True)\n",
    "        numerator = np.exp(X)\n",
    "        denominator = np.sum(numerator, axis=1, keepdims=True)\n",
    "        return np.divide(numerator, denominator)\n",
    "    \n",
    "    def tanh_diff(self, X):\n",
    "        return 1 - np.square(self.tanh(X))\n",
    "    \n",
    "    def sigmoid_diff(self, X):\n",
    "        return np.multiply(self.sigmoid(X), (1-self.sigmoid(X)))\n",
    "    \n",
    "    def ReLU_diff(self, X):\n",
    "        X[X<=0] = 0\n",
    "        X[X>0] = 1\n",
    "        return X\n",
    "    \n",
    "    def softmax_diff(self, X):\n",
    "        return np.multiply(self.softmax(X), (1-self.softmax(X)))\n",
    "    \n",
    "        \n",
    "    def compile_network(self, loss, *args):\n",
    "        \n",
    "        if len(args) == 1:\n",
    "            self.metrics = args[0]\n",
    "        else:\n",
    "            self.metrics = []\n",
    "        self.metrics.insert(0, loss)\n",
    "        self.loss_func_error = self.loss_error_map[loss]\n",
    "        self.loss = loss\n",
    "        \n",
    "    def predict(self, X, return_sequences=False):\n",
    "        self.forward_pass(X)\n",
    "        if self.loss == 'binary_crossentropy':\n",
    "            if return_sequences==False:\n",
    "                return (self.sequences[-1] > 0.5).astype(int)\n",
    "            else:\n",
    "                return (self.sequences > 0.5).astype(int)\n",
    "        else:\n",
    "            if return_sequences==False:\n",
    "                return self.sequences[-1]\n",
    "            else:\n",
    "                return self.sequences\n",
    "        \n",
    "    def clip_gradients(self, grad):\n",
    "        grad[grad>1] = 1\n",
    "        grad[grad<-1] = -1\n",
    "        return grad\n",
    "        \n",
    "    def mse_error(self, y, y_hat):      \n",
    "        n_samples = y.shape[0]\n",
    "        e = -(2/n_samples)*(y-y_hat)\n",
    "        return e\n",
    "            \n",
    "    def bincross_error(self, y, y_hat):     \n",
    "        n_samples = y.shape[0]\n",
    "        e = (1/n_samples)*( -np.divide(y, y_hat+ self.epsilon) + np.divide((1-y), (1-y_hat+ self.epsilon)) )   \n",
    "        return e\n",
    "    \n",
    "    def catcross_error(self, y, y_hat):     \n",
    "        n_classes = y.shape[1]\n",
    "        n_samples = y.shape[0]\n",
    "        e = (1/(n_samples*n_classes))*( -np.divide(y, y_hat + self.epsilon) ) \n",
    "        self.kk = e  \n",
    "        return e\n",
    "\n",
    "    def sparcat_error(self, y, y_hat):\n",
    "        n_samples = y_hat.shape[0]\n",
    "        n_classes = y_hat.shape[1]\n",
    "        sample_inds = np.arange(0, n_samples).reshape(-1, 1)\n",
    "        e = np.zeros(y_hat.shape)\n",
    "        e[sample_inds, y] = 1/(y_hat[sample_inds, y] + self.epsilon)\n",
    "        e = -(1/n_samples*n_classes)*e\n",
    "        self.kk = e\n",
    "        return e\n",
    "    \n",
    "    def calc_mse(self, X, y):\n",
    "        n_samples = y.shape[0]\n",
    "        y_hat = self.predict(X)\n",
    "        return np.sum(np.square(y - y_hat))/n_samples\n",
    "    \n",
    "    def calc_bincross(self, X, y):\n",
    "        n_samples = y.shape[0]\n",
    "        self.forward_pass(X)\n",
    "        y_hat = self.activations[-1]\n",
    "        return -np.sum(np.multiply(y, np.log(y_hat + self.epsilon)) + np.multiply((1-y), np.log(1-y_hat + self.epsilon)) ) / n_samples\n",
    "    \n",
    "    def calc_catcross(self, X, y):\n",
    "        n_samples = y.shape[0]\n",
    "        n_classes = y.shape[1]\n",
    "        self.forward_pass(X)\n",
    "        y_hat = self.activations[-1]\n",
    "        return -np.sum(np.multiply(y, np.log(y_hat + self.epsilon)))/(n_samples*n_classes)\n",
    "    \n",
    "    def calc_sparcat(self, X, y):\n",
    "        n_samples = y.shape[0]\n",
    "        self.forward_pass(X)\n",
    "        y_hat = self.activations[-1]\n",
    "        n_classes = y_hat.shape[1]\n",
    "        sample_inds = np.arange(0, n_samples).reshape(-1, 1)\n",
    "        y_target_probs = y_hat[sample_inds, y]\n",
    "        return -np.sum(np.log(y_target_probs + self.epsilon))/(n_samples*n_classes)\n",
    "\n",
    "    def calc_rmse(self, X, y):\n",
    "        return np.sqrt(self.calc_mse(X, y))    \n",
    "        \n",
    "    def calc_r2(self, X, y):\n",
    "        n_samples = y.shape[0]\n",
    "        y_hat = self.predict(X)\n",
    "        r2 = 1 - (np.sum(np.square(y - y_hat))) / (np.sum(np.square(y - np.mean(y))))\n",
    "        return r2\n",
    "    \n",
    "    def calc_accuracy(self, X, y):\n",
    "        n_samples = y.shape[0]\n",
    "        if self.loss == 'binary_crossentropy':\n",
    "            y_hat = (self.predict(X) > 0.5).astype(int)\n",
    "            return np.sum(y == y_hat) / n_samples\n",
    "        elif self.loss == 'categorical_crossentropy':\n",
    "            y_hat = np.argmax(self.predict(X), axis=1)\n",
    "            y =  np.argmax(y, axis=1)\n",
    "            return np.sum(y == y_hat) / n_samples\n",
    "        elif self.loss == 'sparse_categorical_crossentropy':\n",
    "            y = y.flatten()\n",
    "            y_hat = np.argmax(self.predict(X), axis=1)\n",
    "            return np.sum(y == y_hat) / n_samples\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        \n",
    "        if len(y.shape) == 1:\n",
    "            y = np.expand_dims(y, 1)\n",
    "        \n",
    "        if self.loss == 'mse':\n",
    "            print(f\"Root mean square error: {self.calc_rmse(X, y)}\")\n",
    "            print(f\"R2 score: {self.calc_r2(X, y)}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"Accuracy: {self.calc_accuracy(X, y)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(NN_lib):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        self.layer_map = {'conv':self.conv_pass, 'dense':self.dense_pass, 'flatten':self.flatten_pass, 'pool':self.pool_pass, 'bn':self.bn_pass}\n",
    "        self.pool_map = {'max':np.max, 'avg':np.mean}\n",
    "        \n",
    "    def initialise(self):\n",
    "        self.params = []\n",
    "        self.fixed_params = []\n",
    "        self.layer_type = []\n",
    "        self.activations = []\n",
    "        self.act_shapes = []\n",
    "        \n",
    "    def add(self, layer):\n",
    "        layer\n",
    "    \n",
    "    def Conv(self, n_filters, filter_shape, strides=(1,1), padding=(0, 0), act_func='none', input_shape=None):\n",
    "        if input_shape == None:\n",
    "            input_shape = self.act_shapes[-1]\n",
    "        else:\n",
    "            self.act_shapes.append(input_shape)\n",
    "        self.params.append([(np.random.randn(input_shape[-1], *filter_shape)*2/np.sqrt(sum(list(filter_shape))), 0) for _ in range(n_filters)])\n",
    "        self.fixed_params.append([n_filters, filter_shape, strides, padding, act_func])\n",
    "        self.layer_type.append('conv')\n",
    "        \n",
    "        output_rows = np.floor((input_shape[0] - filter_shape[0] + 2*padding[0])/strides[0]) + 1\n",
    "        output_cols = np.floor((input_shape[1] - filter_shape[1] + 2*padding[1])/strides[1]) + 1\n",
    "        self.act_shapes.append((int(output_rows), int(output_cols), n_filters))\n",
    "        \n",
    "    def Pooling(self, type='max', pool_by=(2,2), strides=None):\n",
    "        if strides == None:\n",
    "            strides = pool_by\n",
    "        self.params.append([])\n",
    "        self.fixed_params.append([type, pool_by, strides])\n",
    "        self.layer_type.append('pool')\n",
    "        \n",
    "        input_shape = self.act_shapes[-1]\n",
    "        output_rows = np.floor((input_shape[0] - pool_by[0])/strides[0]) + 1\n",
    "        output_cols = np.floor((input_shape[1] - pool_by[1])/strides[1]) + 1\n",
    "        self.act_shapes.append((int(output_rows), int(output_cols), self.act_shapes[-1][-1]))\n",
    "        \n",
    "    def BatchNormalisation(self):\n",
    "        self.params.append([])\n",
    "        self.fixed_params.append([])\n",
    "        self.layer_type.append('bn')\n",
    "        \n",
    "        self.act_shapes.append(self.act_shapes[-1])\n",
    "        \n",
    "    def Flatten(self):\n",
    "        self.params.append([])\n",
    "        self.fixed_params.append([])\n",
    "        self.layer_type.append('flatten')\n",
    "        \n",
    "        act_len = 1\n",
    "        for dim_len in self.act_shapes[-1]:\n",
    "            act_len = np.int(act_len*dim_len)\n",
    "            \n",
    "        self.act_shapes.append((act_len,))\n",
    "        \n",
    "    def Dense(self, n_neurons, act_func='none'):\n",
    "        inp_dim = self.act_shapes[-1][0]\n",
    "        self.params.append([np.random.randn(inp_dim, n_neurons)*2/np.sqrt(n_neurons), np.zeros(n_neurons)])\n",
    "        self.fixed_params.append([act_func])\n",
    "        self.layer_type.append('dense')\n",
    "        \n",
    "        self.act_shapes.append((n_neurons,))\n",
    "        \n",
    "    def forward_pass(self, X):\n",
    "        self.activations = [[] for _ in range(len(self.layer_type))]\n",
    "        self.activations.insert(0, X)\n",
    "        for i in range(len(self.params)):\n",
    "            layer_type = self.layer_type[i]\n",
    "            self.activations[i+1] = self.layer_map[layer_type](self.activations[i], i)\n",
    "            \n",
    "    def pad_img(self, img, i):\n",
    "        padding = self.fixed_params[i][3]\n",
    "        \n",
    "        if padding == 'same':\n",
    "            dim_row, dim_col = self.activations[i][1:]\n",
    "            flt_row, flt_col = self.fixed_params[i][1]\n",
    "            str_row, str_col = self.fixed_params[i][2]\n",
    "            pad_row = np.ceil(((dim_row - 1)*str_row)+flt_row-dim_row)\n",
    "            pad_col = np.ceil(((dim_col - 1)*str_col)+flt_col-dim_col)\n",
    "        else:\n",
    "            pad_row, pad_col = padding\n",
    "                \n",
    "        if pad_row % 2 == 0:\n",
    "            pad_top = pad_bottom = int(pad_row/2)   \n",
    "        else:\n",
    "            pad_top = int(pad_row//2)\n",
    "            pad_bottom = int(pad_row - pad_top)\n",
    "            \n",
    "        if pad_col % 2 == 0:\n",
    "            pad_left = pad_right = int(pad_col/2)       \n",
    "        else:\n",
    "            pad_left = int(pad_col//2)\n",
    "            pad_right = int(pad_col - pad_left)\n",
    "            \n",
    "        result = []\n",
    "        for i in range(img.shape[0]):\n",
    "            self.foo = img[i]\n",
    "            result.append(np.pad(img[i], ((pad_top, pad_bottom), (pad_left, pad_right), (0, 0)), 'constant'))\n",
    "        return np.array(result)\n",
    "            \n",
    "    def conv_pass(self, X, i):\n",
    "        \n",
    "        X_padded = self.pad_img(X, i)\n",
    "        activations = []\n",
    "        act_fun = self.act_func_map[self.fixed_params[i][4]]\n",
    "        fil_ver_len, fil_hor_len = self.fixed_params[i][1][0], self.fixed_params[i][1][1]\n",
    "        max_hor, max_ver = X_padded.shape[1]-1, X_padded.shape[2]-1\n",
    "        \n",
    "        for kernel in self.params[i]:\n",
    "            \n",
    "            act_layer = []\n",
    "            act_single_row = []\n",
    "            hor_pointer, ver_pointer = 0, 0\n",
    "            \n",
    "            while(ver_pointer + fil_ver_len -1 <= max_ver):\n",
    "                \n",
    "                img_portion = X_padded[:, hor_pointer:hor_pointer+fil_hor_len, ver_pointer:ver_pointer+fil_ver_len, :]\n",
    "                act_single_row.append(act_fun(np.sum(np.multiply(img_portion, kernel[0]) + kernel[1])))\n",
    "            \n",
    "                if (hor_pointer + fil_hor_len -1 > max_hor):\n",
    "                    act_layer.append(act_single_row)\n",
    "                    act_single_row = []\n",
    "                    hor_pointer = 0\n",
    "                    ver_pointer = ver_pointer + self.fixed_params[i][2][1]\n",
    "                \n",
    "                else:\n",
    "                    hor_pointer = hor_pointer + self.fixed_params[i][2][0]\n",
    "           \n",
    "            activations.append(act_layer)    \n",
    "        return np.array(activations)\n",
    "        \n",
    "    def pool_pass(self, X, i):\n",
    "        activations = []\n",
    "        pool_ver_len, pool_hor_len = self.fixed_params[i][1][0], self.fixed_params[i][1][1]\n",
    "        max_hor, max_ver = X.shape[1], X.shape[2]\n",
    "        \n",
    "        for activation in X:\n",
    "            act_layer = []\n",
    "            act_single_row = []\n",
    "            hor_pointer, ver_pointer = 0, 0\n",
    "            \n",
    "            while(ver_pointer + pool_ver_len -1 <= max_ver):\n",
    "                \n",
    "                act_portion = activation[hor_pointer:hor_pointer+pool_hor_len, ver_pointer:ver_pointer+pool_ver_len]\n",
    "                act_single_row.append(self.pool_map[self.fixed_params[i][0]](act_portion))\n",
    "                if (hor_pointer + pool_hor_len -1 > max_hor):\n",
    "                    act_layer.append(act_single_row)\n",
    "                    act_single_row = []\n",
    "                    hor_pointer = 0\n",
    "                    ver_pointer = ver_pointer + pool_ver_len - 1 + self.fixed_params[i][2][1]\n",
    "                \n",
    "                else:\n",
    "                    hor_pointer = hor_pointer + pool_hor_len -1 + self.fixed_params[i][2][0]\n",
    "           \n",
    "            activations.append(act_layer)\n",
    "        return np.array(activations)\n",
    "        \n",
    "    def bn_pass(self, X, i):\n",
    "        mean = np.dstack([np.mean(X, axis=-1)]*X.shape[-1])\n",
    "        std = np.dstack([np.std(X, axis=-1)]*X.shape[-1])\n",
    "        return np.divide(np.subtract(X, mean), std + self.epsilon)\n",
    "    \n",
    "    def flatten_pass(self, X, i):\n",
    "        return X.reshape(X.shape[0], -1)\n",
    "    \n",
    "    def dense_pass(self, X, i):\n",
    "        act_func = self.act_func_map[self.fixed_params[i][0]]\n",
    "        return act_func(np.dot(X, self.params[i][0]) + self.params[i][1])  \n",
    "    \n",
    "    def summary(self, input_shape):\n",
    "        table_top = '-'*86\n",
    "        print(table_top)\n",
    "        contents = []\n",
    "        col_len = [16, 44, 20]\n",
    "        contents.append(['Layer', 'Parameters', 'Activations'])\n",
    "        for i in range(len(self.layer_type)):          \n",
    "            if self.layer_type[i] == 'conv':\n",
    "                params = f'{self.fixed_params[i][0]} filters of shape {self.fixed_params[i][1]}'       \n",
    "            elif self.layer_type[i] == 'dense':\n",
    "                params = f'weights: {self.params[i][0].shape}, biases: {self.params[i][1].shape}'        \n",
    "            else:\n",
    "                params = '[]'             \n",
    "            contents.append([self.layer_type[i], params, f'{self.act_shapes[1:][i]}'])\n",
    "            \n",
    "        for item in contents:\n",
    "            show = '|'\n",
    "            for i in range(len(item)):\n",
    "                space_gap =  ' '*int((col_len[i]-len(item[i]))/2)\n",
    "                show = show + space_gap + item[i] + space_gap + '|'\n",
    "                              \n",
    "            print(show)\n",
    "            print(table_top)\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------\n",
      "|     Layer     |                 Parameters                 |    Activations    |\n",
      "--------------------------------------------------------------------------------------\n",
      "|      conv      |         16 filters of shape (3, 3)         |    (26, 26, 16)    |\n",
      "--------------------------------------------------------------------------------------\n",
      "|      pool      |                     []                     |    (13, 13, 16)    |\n",
      "--------------------------------------------------------------------------------------\n",
      "|       bn       |                     []                     |    (13, 13, 16)    |\n",
      "--------------------------------------------------------------------------------------\n",
      "|      conv      |         16 filters of shape (3, 3)         |     (6, 6, 16)     |\n",
      "--------------------------------------------------------------------------------------\n",
      "|      pool      |                     []                     |     (3, 3, 16)     |\n",
      "--------------------------------------------------------------------------------------\n",
      "|       bn       |                     []                     |     (3, 3, 16)     |\n",
      "--------------------------------------------------------------------------------------\n",
      "|    flatten    |                     []                     |       (144,)       |\n",
      "--------------------------------------------------------------------------------------\n",
      "|     dense     |     weights: (144, 10), biases: (10,)     |       (10,)       |\n",
      "--------------------------------------------------------------------------------------\n",
      "|     dense     |       weights: (10, 1), biases: (1,)       |        (1,)        |\n",
      "--------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.initialise()\n",
    "\n",
    "model.add(model.Conv(16, (3,3), act_func='relu', input_shape=(28, 28, 1)))\n",
    "model.add(model.Pooling('avg', (2, 2)))\n",
    "model.add(model.BatchNormalisation())\n",
    "          \n",
    "model.add(model.Conv(16, (3,3), strides = (2, 2), act_func='relu'))\n",
    "model.add(model.Pooling('max', (2, 2)))\n",
    "model.add(model.BatchNormalisation())\n",
    "\n",
    "model.add(model.Flatten())\n",
    "model.add(model.Dense(10, act_func='relu'))\n",
    "model.add(model.Dense(1, act_func='relu'))\n",
    "\n",
    "model.summary((28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = np.expand_dims(X_train[:1000], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with remapped shapes [original->remapped]: (3,2) and requested shape (2,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-4286c6e1e626>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-3e609f30dd24>\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mlayer_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpad_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-3e609f30dd24>\u001b[0m in \u001b[0;36mconv_pass\u001b[0;34m(self, X, i)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconv_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mX_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mact_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_func_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-3e609f30dd24>\u001b[0m in \u001b[0;36mpad_img\u001b[0;34m(self, img, i)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfoo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_top\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_bottom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpad_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'constant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mpad\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0;31m# Broadcast to shape (array.ndim, 2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m     \u001b[0mpad_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/arraypad.py\u001b[0m in \u001b[0;36m_as_pairs\u001b[0;34m(x, ndim, as_index)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;31m# Converting the array with `tolist` seems to improve performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;31m# when iterating and indexing the result (see usage in `pad`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbroadcast_to\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_to\u001b[0;34m(array, shape, subok)\u001b[0m\n\u001b[1;32m    180\u001b[0m            [1, 2, 3]])\n\u001b[1;32m    181\u001b[0m     \"\"\"\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_broadcast_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_to\u001b[0;34m(array, shape, subok, readonly)\u001b[0m\n\u001b[1;32m    125\u001b[0m     it = np.nditer(\n\u001b[1;32m    126\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'multi_index'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'refs_ok'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zerosize_ok'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextras\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         op_flags=['readonly'], itershape=shape, order='C')\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m# never really has writebackifcopy semantics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with remapped shapes [original->remapped]: (3,2) and requested shape (2,2)"
     ]
    }
   ],
   "source": [
    "model.forward_pass(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.foo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 9, 10)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.activations[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
